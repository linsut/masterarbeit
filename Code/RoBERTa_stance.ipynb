{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa for Stance detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and installs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports for SimpleTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import re\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read files\n",
    "Only execute one of these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake News Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:5159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "stances = pd.read_csv('data/stance/train_stances.csv')\n",
    "bodies = pd.read_csv('data/stance/train_bodies.csv')\n",
    "\n",
    "stances = stances.set_index(stances['Body ID']).drop('Body ID', axis = 1)\n",
    "bodies = bodies.set_index(bodies['Body ID']).drop('Body ID', axis = 1)\n",
    "\n",
    "data = stances.join(bodies)\n",
    "\n",
    "data.rename(columns={\"Headline\": \"text_a\", \"articleBody\": \"text_b\", \"Stance\" : \"labels\"}, inplace=True)\n",
    "data = data[['text_a', 'text_b', 'labels']]\n",
    "\n",
    "data.text_b = data.text_b.map(lambda x : x.translate(str.maketrans('', '', string.punctuation)))\n",
    "data.text_a = data.text_a.map(lambda x : x.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "data.text_a = data.text_a.str.lower()\n",
    "data.text_b = data.text_b.str.lower()\n",
    "\n",
    "data.text_a = data.text_a.str.strip(string.whitespace)\n",
    "data.text_b = data.text_b.str.strip(string.whitespace)\n",
    "\n",
    "df_train, df_test = train_test_split(data, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "thisdict =\t{\n",
    "  \"unrelated\": 0,\n",
    "  \"agree\": 1,\n",
    "  \"discuss\": 2,\n",
    "  \"disagree\": 3\n",
    "}\n",
    "df_train.labels = df_train.labels.apply(lambda x: thisdict[x])\n",
    "df_test.labels = df_test.labels.apply(lambda x: thisdict[x])\n",
    "\n",
    "df_train.reset_index(inplace=True, drop = True)\n",
    "df_test.reset_index(inplace=True, drop = True)\n",
    "\n",
    "\n",
    "num_stances = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>text_b</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>american bombing had signed my death certifica...</td>\n",
       "      <td>a schoolboy who was almost killed when he was ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>isis border crisis dhs chief says terrorists n...</td>\n",
       "      <td>the pentagon has confirmed that the weapons we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kevin vickers sergeantatarms shoots a shooting...</td>\n",
       "      <td>two friends have a 20yearold mcdonald’s quarte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that story about a catholic priest dying seein...</td>\n",
       "      <td>absolutely awful news media are reporting that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>its rubbish that robert plant turned down £500...</td>\n",
       "      <td>robert plant’s publicist has described as “rub...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33476</th>\n",
       "      <td>hbo streaming service could launch in april fo...</td>\n",
       "      <td>cnn  the mystery surrounding north koreas erra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33477</th>\n",
       "      <td>news youll never guess how a homeless man spen...</td>\n",
       "      <td>you know that tendency we have to judge people...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33478</th>\n",
       "      <td>hostage david haines murder evil pm says</td>\n",
       "      <td>when a report went viral that nbc meteorologis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33479</th>\n",
       "      <td>isis leader dead</td>\n",
       "      <td>new delhi ak verma an executive engineer at th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33480</th>\n",
       "      <td>best christmas present ever heartwarming momen...</td>\n",
       "      <td>iraqi pilots who have joined islamic state are...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33481 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text_a  \\\n",
       "0      american bombing had signed my death certifica...   \n",
       "1      isis border crisis dhs chief says terrorists n...   \n",
       "2      kevin vickers sergeantatarms shoots a shooting...   \n",
       "3      that story about a catholic priest dying seein...   \n",
       "4      its rubbish that robert plant turned down £500...   \n",
       "...                                                  ...   \n",
       "33476  hbo streaming service could launch in april fo...   \n",
       "33477  news youll never guess how a homeless man spen...   \n",
       "33478           hostage david haines murder evil pm says   \n",
       "33479                                   isis leader dead   \n",
       "33480  best christmas present ever heartwarming momen...   \n",
       "\n",
       "                                                  text_b  labels  \n",
       "0      a schoolboy who was almost killed when he was ...       0  \n",
       "1      the pentagon has confirmed that the weapons we...       0  \n",
       "2      two friends have a 20yearold mcdonald’s quarte...       0  \n",
       "3      absolutely awful news media are reporting that...       0  \n",
       "4      robert plant’s publicist has described as “rub...       1  \n",
       "...                                                  ...     ...  \n",
       "33476  cnn  the mystery surrounding north koreas erra...       0  \n",
       "33477  you know that tendency we have to judge people...       1  \n",
       "33478  when a report went viral that nbc meteorologis...       0  \n",
       "33479  new delhi ak verma an executive engineer at th...       0  \n",
       "33480  iraqi pilots who have joined islamic state are...       0  \n",
       "\n",
       "[33481 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SemEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/stance/trainingdata-all-annotations.txt', delimiter='\\t', encoding='iso8859-2')\n",
    "df_test = pd.read_csv('data/stance/testdata-taskA-all-annotations.txt', delimiter='\\t'\n",
    "                     ).append(pd.read_csv('data/stance/testdata-taskB-all-annotations.txt', delimiter='\\t'))\n",
    "\n",
    "\n",
    "df_train.drop(['ID', 'Opinion towards', 'Sentiment'], axis=1, inplace=True)\n",
    "df_test.drop(['ID', 'Opinion towards', 'Sentiment'], axis = 1, inplace=True)\n",
    "\n",
    "df_train.rename(columns={\"Target\": \"text_a\", \"Tweet\": \"text_b\", \"Stance\" : \"labels\"}, inplace=True)\n",
    "df_test.rename(columns={\"Target\": \"text_a\", \"Tweet\": \"text_b\", \"Stance\" : \"labels\"}, inplace=True)\n",
    "\n",
    "df_train.text_b = df_train.text_b.apply(lambda x:re.sub(r'http\\S+', '', x))\n",
    "df_test.text_b = df_test.text_b.apply(lambda x:re.sub(r'http\\S+', '', x))\n",
    "\n",
    "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "df_train.text_b = df_train.text_b.apply(lambda x: tokenizer.tokenize(x))\n",
    "df_test.text_b = df_test.text_b.apply(lambda x: tokenizer.tokenize(x))\n",
    "\n",
    "df_train.text_b = df_train.text_b.apply(lambda x: ' '.join(x))\n",
    "df_test.text_b = df_test.text_b.apply(lambda x: ' '.join(x))\n",
    "\n",
    "df_train.text_b = df_train.text_b.map(lambda x : x.translate(str.maketrans('', '', string.punctuation)))\n",
    "df_test.text_b = df_test.text_b.map(lambda x : x.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "df_train.text_a = df_train.text_a.str.lower()\n",
    "df_train.text_b = df_train.text_b.str.lower()\n",
    "df_test.text_a = df_test.text_a.str.lower()\n",
    "df_test.text_b = df_test.text_b.str.lower()\n",
    "\n",
    "df_train.text_b = df_train.text_b.str.strip(string.whitespace)\n",
    "df_test.text_b = df_test.text_b.str.strip(string.whitespace)\n",
    "\n",
    "\n",
    "df_train.reset_index(inplace=True, drop = True)\n",
    "df_test.reset_index(inplace=True, drop = True)\n",
    "\n",
    "\n",
    "thisdict =\t{\n",
    "  \"AGAINST\": 0,\n",
    "  \"FAVOR\": 1,\n",
    "  \"NONE\": 2\n",
    "}\n",
    "df_train.labels = df_train.labels.apply(lambda x: thisdict[x])\n",
    "df_test.labels = df_test.labels.apply(lambda x: thisdict[x])\n",
    "\n",
    "num_stances = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>text_b</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atheism</td>\n",
       "      <td>dear lord thank u for all of ur blessings forg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atheism</td>\n",
       "      <td>blessed are the peacemakers  for they shall be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atheism</td>\n",
       "      <td>i am not conformed to this world  i am transfo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atheism</td>\n",
       "      <td>salah should be prayed with focus and understa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atheism</td>\n",
       "      <td>and stay in your houses and do not display you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>legalization of abortion</td>\n",
       "      <td>theres a law protecting unborn eagles  but not...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2810</th>\n",
       "      <td>legalization of abortion</td>\n",
       "      <td>i am 1 in 3  i have had an abortion abortionon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>legalization of abortion</td>\n",
       "      <td>how dare you say my sexual preference is a cho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>legalization of abortion</td>\n",
       "      <td>equal rights for those  born that way   no rig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2813</th>\n",
       "      <td>legalization of abortion</td>\n",
       "      <td>potus seals his legacy w  12 doz wins  the gop...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2814 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        text_a  \\\n",
       "0                      atheism   \n",
       "1                      atheism   \n",
       "2                      atheism   \n",
       "3                      atheism   \n",
       "4                      atheism   \n",
       "...                        ...   \n",
       "2809  legalization of abortion   \n",
       "2810  legalization of abortion   \n",
       "2811  legalization of abortion   \n",
       "2812  legalization of abortion   \n",
       "2813  legalization of abortion   \n",
       "\n",
       "                                                 text_b  labels  \n",
       "0     dear lord thank u for all of ur blessings forg...       0  \n",
       "1     blessed are the peacemakers  for they shall be...       0  \n",
       "2     i am not conformed to this world  i am transfo...       0  \n",
       "3     salah should be prayed with focus and understa...       0  \n",
       "4     and stay in your houses and do not display you...       0  \n",
       "...                                                 ...     ...  \n",
       "2809  theres a law protecting unborn eagles  but not...       0  \n",
       "2810  i am 1 in 3  i have had an abortion abortionon...       0  \n",
       "2811  how dare you say my sexual preference is a cho...       0  \n",
       "2812  equal rights for those  born that way   no rig...       0  \n",
       "2813  potus seals his legacy w  12 doz wins  the gop...       0  \n",
       "\n",
       "[2814 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3083f1b0b943b1a975f917a2f55833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=33481.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce0d0d12fe540e7bf324edc5151a2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=10.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2091c827e42747548c9988cf3a16dd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0', max=2093.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.218580"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.096102"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.112723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346cb10779c747cbab335a873a91105d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 1', max=2093.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.553354\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f9efd15cf8461bab3d26b7fc7ad8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 2', max=2093.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.051245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec68b582505460da91f4af572a25259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 3', max=2093.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.001406\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b01457d1b7d4543be09ba5edecac8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 4', max=2093.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.010484\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec5cbecc8b444989be5355736233744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 5', max=2093.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.000097\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a417e75beaa948738ce22d5616fbbcad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 6', max=2093.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.000474\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e498fec73a4b25b6f0c239bdced169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 7', max=2093.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.000317\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690f547b58a84dcb816257bf1963636b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 8', max=2093.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.000185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e083e7f804441c7a36788a49927b6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 9', max=2093.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.000526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel('roberta', 'roberta-base', num_labels=num_stances, args={\n",
    "    'learning_rate':3e-5,\n",
    "    'num_train_epochs': 10,\n",
    "    'reprocess_input_data': True,\n",
    "    'overwrite_output_dir': True,\n",
    "    'process_count': 10,\n",
    "    'train_batch_size': 16,\n",
    "    'eval_batch_size': 16,\n",
    "    'max_seq_length': 512,\n",
    "    'n_gpu' : 16,\n",
    "    'fp16': False\n",
    "})\n",
    "\n",
    "model.train_model(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523fd4ca23784992bda624639c1d8e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16491.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594a8ec707904a059674f8c82d783ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Evaluation', max=1031.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "_, model_outputs_test, _ = model.eval_model(df_test)\n",
    "\n",
    "preds_test = np.argmax(model_outputs_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99866778 0.96532028 0.98332221 0.93203883]\n",
      "0.9923594688011643\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "print(f1_score(df_test.labels, preds_test, average=None))\n",
    "print(accuracy_score(df_test.labels, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
